# Dossier où stocker/charger les GGUF
MODELS_DIR=/models

# Modèle actif (chemin absolu ou relatif)
MODEL_PATH=/models/gemma-3-270m-it-Q4_K_M.gguf

# Paramètres inference CPU
N_THREADS=8
N_CTX=4096
N_BATCH=256
N_GPU_LAYERS=0
LLM_VERBOSE=0

# Réseau
HOST=0.0.0.0
PORT=8000
FLASK_DEBUG=0

# (Optionnel) Cache HF
# HF_HOME=/hf_cache